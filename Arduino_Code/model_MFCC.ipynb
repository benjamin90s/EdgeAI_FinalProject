{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 3.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting setuptools\n",
            "  Downloading setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 19.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting wheel\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[31mERROR: launchpadlib 1.10.13 requires testresources, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.13.1 has requirement typing-extensions<4.6.0,>=3.6.6, but you'll have typing-extensions 4.13.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pip, setuptools, wheel\n",
            "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.8 are installed in '/home/adityab/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.3.0\n",
            "    Uninstalling setuptools-75.3.0:\n",
            "      Successfully uninstalled setuptools-75.3.0\n",
            "\u001b[33m  WARNING: The script wheel is installed in '/home/adityab/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed pip-25.0.1 setuptools-75.3.2 wheel-0.45.1\n",
            "Files removed: 440 (7201.0 MB)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting librosa\n",
            "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting audioread>=2.1.9 (from librosa)\n",
            "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting numba>=0.51.0 (from librosa)\n",
            "  Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /home/adityab/.local/lib/python3.8/site-packages (from librosa) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /home/adityab/.local/lib/python3.8/site-packages (from librosa) (1.9.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /home/adityab/.local/lib/python3.8/site-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: joblib>=1.0 in /home/adityab/.local/lib/python3.8/site-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /home/adityab/.local/lib/python3.8/site-packages (from librosa) (5.1.1)\n",
            "Collecting soundfile>=0.12.1 (from librosa)\n",
            "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
            "Collecting pooch>=1.1 (from librosa)\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting soxr>=0.3.2 (from librosa)\n",
            "  Downloading soxr-0.3.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /home/adityab/.local/lib/python3.8/site-packages (from librosa) (4.13.0)\n",
            "Collecting lazy_loader>=0.1 (from librosa)\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting msgpack>=1.0 (from librosa)\n",
            "  Downloading msgpack-1.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: packaging in /home/adityab/.local/lib/python3.8/site-packages (from lazy_loader>=0.1->librosa) (24.1)\n",
            "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.51.0->librosa)\n",
            "  Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: importlib-metadata in /home/adityab/.local/lib/python3.8/site-packages (from numba>=0.51.0->librosa) (8.2.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /home/adityab/.local/lib/python3.8/site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /home/adityab/.local/lib/python3.8/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/adityab/.local/lib/python3.8/site-packages (from scikit-learn>=1.1.0->librosa) (3.5.0)\n",
            "Collecting cffi>=1.0 (from soundfile>=0.12.1->librosa)\n",
            "  Downloading cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->librosa)\n",
            "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/adityab/.local/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/adityab/.local/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/adityab/.local/lib/python3.8/site-packages (from importlib-metadata->numba>=0.51.0->librosa) (3.20.0)\n",
            "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
            "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Downloading msgpack-1.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
            "Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading soxr-0.3.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
            "Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "\u001b[33mWARNING: Error parsing dependencies of distro-info: Invalid version: '0.23ubuntu1'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of python-debian: Invalid version: '0.1.36ubuntu1'\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: soxr, pycparser, msgpack, llvmlite, lazy_loader, audioread, pooch, numba, cffi, soundfile, librosa\n",
            "Successfully installed audioread-3.0.1 cffi-1.17.1 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.41.1 msgpack-1.1.0 numba-0.58.1 pooch-1.8.2 pycparser-2.22 soundfile-0.13.1 soxr-0.3.7\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install --upgrade pip setuptools wheel\n",
        "!{sys.executable} -m pip cache purge\n",
        "!{sys.executable} -m pip install librosa\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4ZP0uXOIeLQd"
      },
      "outputs": [],
      "source": [
        "# 🛠️ 1. Import libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import librosa\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF7G2m99ltDj",
        "outputId": "4d83a9c3-f0fb-4986-8dd8-e7915734bd20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2melK7Ylzsu",
        "outputId": "e4ea4e97-2dcd-49f5-9db8-54df70692d02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['crow_dataset',\n",
              " 'Rose_ringed_Parkeet',\n",
              " 'Noise',\n",
              " 'hen_cock-export',\n",
              " 'Asean_Koel',\n",
              " '.DS_Store']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/home/adityab/ADRL/A1/edge/dataset/data'\n",
        "os.listdir(folder_path)  # Lists contents of the folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v59btXRDmaT8",
        "outputId": "978ae583-8bbc-43f8-a8ee-affc4c9fd8ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling rate (Hz): 16000\n",
            "Audio duration (sec): 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2422261/3889777116.py:7: WavFileWarning: Reached EOF prematurely; finished at 32044 bytes, expected 32052 bytes from header.\n",
            "  sample_rate, data = wavfile.read(file_path)\n"
          ]
        }
      ],
      "source": [
        "from scipy.io import wavfile\n",
        "\n",
        "# Replace with the path to your .wav file\n",
        "file_path = '/home/adityab/ADRL/A1/edge/dataset/data/Rose_ringed_Parkeet/Rose-ringed Parakeet.5polkukm.ingestion-54c4c64498-k9fpq.s1.wav'\n",
        "\n",
        "# Read the WAV file\n",
        "sample_rate, data = wavfile.read(file_path)\n",
        "\n",
        "print(\"Sampling rate (Hz):\", sample_rate)\n",
        "print(\"Audio duration (sec):\", len(data) / sample_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wSGk9auetqt",
        "outputId": "1b36f810-e606-49e0-e251-4a1e2520d57e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (2518, 13, 32, 1), Labels shape: (2518,)\n"
          ]
        }
      ],
      "source": [
        "# 🛠️ 2. Prepare your dataset\n",
        "DATASET_PATH = folder_path  # replace with your path\n",
        "commands = ['Asean_Koel', 'crow_dataset', 'hen_cock-export', 'Noise', 'Rose_ringed_Parkeet']\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "DURATION = 1  # 1 second clips\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
        "\n",
        "# Load and process audio files\n",
        "for label_idx, label in enumerate(commands):\n",
        "    folder_path = os.path.join(DATASET_PATH, label)\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith(\".wav\"):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            audio, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "            if len(audio) < SAMPLES_PER_TRACK:\n",
        "                audio = np.pad(audio, (0, SAMPLES_PER_TRACK - len(audio)))\n",
        "            else:\n",
        "                audio = audio[:SAMPLES_PER_TRACK]\n",
        "\n",
        "            # Simulate MFCC extraction as TensorFlow Lite Micro does\n",
        "            mfcc = librosa.feature.mfcc(y=audio, sr=SAMPLE_RATE, n_mfcc=13)\n",
        "            mfcc = np.expand_dims(mfcc, axis=-1)  # (13, time_steps, 1)\n",
        "\n",
        "            X.append(mfcc)\n",
        "            Y.append(label_idx)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}, Labels shape: {Y.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "g2FZI0Wqm08M",
        "outputId": "bd00e920-1788-4344-beaf-8044119f53bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 11, 30, 8)         80        \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 5, 15, 8)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 3, 13, 16)         1168      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 1, 6, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 96)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                3104      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4517 (17.64 KB)\n",
            "Trainable params: 4517 (17.64 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 🛠️ 3. Train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 🛠️ 4. Build Tiny CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(8, (3,3), activation='relu', input_shape=X_train.shape[1:]),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(16, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(commands), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrRAiYApoLEj",
        "outputId": "89869838-820a-464f-aa44-db75f070476c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3.9890 - accuracy: 0.5392 - val_loss: 1.2710 - val_accuracy: 0.7282\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.7859 - accuracy: 0.7974 - val_loss: 0.6924 - val_accuracy: 0.8194\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4970 - accuracy: 0.8635 - val_loss: 0.5837 - val_accuracy: 0.8651\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8873 - val_loss: 0.4495 - val_accuracy: 0.8810\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.2784 - accuracy: 0.9196 - val_loss: 0.3950 - val_accuracy: 0.9028\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.2419 - accuracy: 0.9384 - val_loss: 0.3128 - val_accuracy: 0.9187\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.2015 - accuracy: 0.9474 - val_loss: 0.3291 - val_accuracy: 0.9187\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.1867 - accuracy: 0.9484 - val_loss: 0.3174 - val_accuracy: 0.9127\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.1516 - accuracy: 0.9598 - val_loss: 0.2789 - val_accuracy: 0.9266\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.1572 - accuracy: 0.9508 - val_loss: 0.2583 - val_accuracy: 0.9325\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.1291 - accuracy: 0.9613 - val_loss: 0.2352 - val_accuracy: 0.9464\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.1278 - accuracy: 0.9623 - val_loss: 0.2467 - val_accuracy: 0.9464\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.1130 - accuracy: 0.9692 - val_loss: 0.2435 - val_accuracy: 0.9444\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.1060 - accuracy: 0.9667 - val_loss: 0.2338 - val_accuracy: 0.9425\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0908 - accuracy: 0.9732 - val_loss: 0.2352 - val_accuracy: 0.9325\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0820 - accuracy: 0.9722 - val_loss: 0.1990 - val_accuracy: 0.9444\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.9767 - val_loss: 0.1913 - val_accuracy: 0.9504\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0625 - accuracy: 0.9826 - val_loss: 0.2125 - val_accuracy: 0.9544\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9801 - val_loss: 0.2013 - val_accuracy: 0.9504\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9846 - val_loss: 0.1668 - val_accuracy: 0.9544\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0456 - accuracy: 0.9896 - val_loss: 0.1715 - val_accuracy: 0.9524\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9846 - val_loss: 0.1962 - val_accuracy: 0.9444\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 0.9851 - val_loss: 0.1980 - val_accuracy: 0.9504\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9846 - val_loss: 0.1795 - val_accuracy: 0.9524\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0371 - accuracy: 0.9876 - val_loss: 0.2085 - val_accuracy: 0.9484\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 0.9886 - val_loss: 0.1668 - val_accuracy: 0.9583\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0351 - accuracy: 0.9901 - val_loss: 0.1648 - val_accuracy: 0.9504\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 0.9906 - val_loss: 0.2305 - val_accuracy: 0.9504\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 0.9921 - val_loss: 0.1609 - val_accuracy: 0.9623\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0196 - accuracy: 0.9955 - val_loss: 0.1645 - val_accuracy: 0.9583\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 0.1607 - val_accuracy: 0.9583\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9926 - val_loss: 0.1811 - val_accuracy: 0.9583\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9970 - val_loss: 0.1944 - val_accuracy: 0.9484\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.9990 - val_loss: 0.1702 - val_accuracy: 0.9563\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9990 - val_loss: 0.1481 - val_accuracy: 0.9583\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.1627 - val_accuracy: 0.9583\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.2403 - val_accuracy: 0.9345\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.1543 - val_accuracy: 0.9623\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 0.1521 - val_accuracy: 0.9603\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.1655 - val_accuracy: 0.9623\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.1695 - val_accuracy: 0.9583\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.2060 - val_accuracy: 0.9544\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.2048 - val_accuracy: 0.9524\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 0.1625 - val_accuracy: 0.9663\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.1630 - val_accuracy: 0.9663\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.9955 - val_loss: 0.2287 - val_accuracy: 0.9563\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: 0.2262 - val_accuracy: 0.9544\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9935 - val_loss: 0.1955 - val_accuracy: 0.9524\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.9801 - val_loss: 0.1859 - val_accuracy: 0.9643\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0409 - accuracy: 0.9881 - val_loss: 0.1968 - val_accuracy: 0.9722\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9940 - val_loss: 0.1817 - val_accuracy: 0.9623\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 0.9975 - val_loss: 0.1895 - val_accuracy: 0.9683\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.1682 - val_accuracy: 0.9663\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1633 - val_accuracy: 0.9643\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 9.9495e-04 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9663\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 7.9836e-04 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9643\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 7.4601e-04 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9663\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 6.8199e-04 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9643\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 6.3808e-04 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9663\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 5.9524e-04 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9663\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 5.7270e-04 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9663\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 5.3325e-04 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9643\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 4.9972e-04 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9663\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 4.8645e-04 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9643\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 4.5300e-04 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9643\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 4.3510e-04 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9643\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 4.1833e-04 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9643\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 3.9836e-04 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9663\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 3.7258e-04 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9663\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 3.7007e-04 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9663\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 3.6707e-04 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9643\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 3.3536e-04 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 0.9643\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 3.2243e-04 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 0.9643\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 3.1708e-04 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9663\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2.9593e-04 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9663\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2.8628e-04 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 0.9643\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2.6889e-04 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9643\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2.5559e-04 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9643\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 2.5305e-04 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 0.9643\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2.4305e-04 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9643\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 2.2667e-04 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9643\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2.2508e-04 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9643\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2.1144e-04 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9643\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2.0250e-04 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9643\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 2.0001e-04 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9643\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.9042e-04 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9643\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.8448e-04 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9643\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.7702e-04 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9663\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.7087e-04 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9643\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.6473e-04 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9643\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.5885e-04 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9663\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.5371e-04 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9643\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.4864e-04 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9643\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.4048e-04 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9643\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.3629e-04 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9643\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.3191e-04 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9643\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.2776e-04 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9643\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.2436e-04 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9643\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.1935e-04 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9643\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.1121e-04 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9643\n"
          ]
        }
      ],
      "source": [
        "# 🛠️ 5. Train model\n",
        "history = model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmAc1BzmoRIV",
        "outputId": "3a60ebf1-673e-4ac0-ce65-86cf4deb622b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9643\n",
            "Test accuracy: 96.43%\n"
          ]
        }
      ],
      "source": [
        "# 🛠️ 6. Evaluate\n",
        "loss, acc = model.evaluate(X_test, Y_test)\n",
        "print(f\"Test accuracy: {acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp16zakvdx/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp16zakvdx/assets\n",
            "2025-05-02 03:42:47.993757: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-05-02 03:42:47.993848: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-05-02 03:42:47.994401: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp16zakvdx\n",
            "2025-05-02 03:42:47.996478: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-05-02 03:42:47.996521: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmp16zakvdx\n",
            "2025-05-02 03:42:48.007781: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
            "2025-05-02 03:42:48.009858: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-05-02 03:42:48.061706: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmp16zakvdx\n",
            "2025-05-02 03:42:48.075939: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 81537 microseconds.\n",
            "2025-05-02 03:42:48.114566: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
          ]
        }
      ],
      "source": [
        "# Convert to TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model\n",
        "with open(\"model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvlRM9eWp6cK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
